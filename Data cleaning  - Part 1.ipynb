{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c31dddd9",
   "metadata": {},
   "source": [
    "**Data Cleaning**\n",
    "\n",
    "In this work we are trying to clean our datasets using wide range of techniques. We start off by importing our dataset, identify the missing values, learn about scaling and normalizing techniques, and end with parsing and encoding tasks. \n",
    "\n",
    "For this project we are using the airbnb dataset on listing of houses in NYC. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543047e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install plotly_express"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacae404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries we'll use\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None)\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly_express as px\n",
    "import os\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0679f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read your data\n",
    "df = pd.read_csv(r\"C:\\Users\\afard\\Downloads\\Airbnb_Open_Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a924c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0fecf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sometimes it is better to look at some random observations rahter than just the top 5\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b3e612",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd54a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b290bdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can simply see the total number of missing observations in each features\n",
    "\n",
    "missing_df_count = df.isnull().sum()\n",
    "missing_df_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5c3c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I like to see them in a sorted way \n",
    "\n",
    "df.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92342095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get an overview of what 5 of our dataset is missing, we can use the following\n",
    "\n",
    "total_obs = np.product(df.shape)\n",
    "total_missing = missing_df_count.sum()\n",
    "\n",
    "# percent of data that is missing\n",
    "(total_missing/total_obs) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af99e374",
   "metadata": {},
   "source": [
    "**7% of our entire observations are missing** \n",
    "\n",
    "Depending on your work, this could be a lot of not much. I think I can live with it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d63bc5e",
   "metadata": {},
   "source": [
    "out of 102599 observations, it seems like the variable *licence* is missing in 102597 cases. So we will definitely drop this variable, however, I like to look at the cases that actually have this variables (2 obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23610433",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[~df.license.isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625c65e3",
   "metadata": {},
   "source": [
    "**Christina** is the only licenced airbnb host in the entire NYC. Nice!\n",
    "\n",
    "Another interesting thing is that the same place (given the NAME and address) is registered using two id numbers. This is a red flag (even though we were not looking for one), that there are potential duplications in our dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfa574d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get rid of licence column\n",
    "\n",
    "df=df.drop(columns=['license'])\n",
    "\n",
    "# you can use this as well\n",
    "# df.drop('license', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfb24af",
   "metadata": {},
   "source": [
    "**Missing values: to drop or not?**\n",
    "\n",
    "I think before we can answer to this important philosophical question, we need to know why the data is missing? (out of all the questions in the current state of world)\n",
    "\n",
    "Essentially, the question is whether the data **does not exist** (like house rules for the host who does not have any rules), or\n",
    "is it because it **does not recorded** (Like country variable: I guess we all can agree that NYC is in Japan). \n",
    "\n",
    "Knowing the answer to this question can help us to either drop the variable (Impute the bastard!) or try to replace it (i just spent 2 hours to read the literature on the best way to replace a missing value and do not have any good answer). But if you feel like reading 100 pages of a paper check this paper out\n",
    "\n",
    "https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4106794\n",
    "\n",
    "Make sure to stay some time and study your dataset before choosing either of these options. Some datasets have documentation that can help you understand the nature of the data, hence, why is it missing?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79e3e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's drop any duplicate observations based on id and Name- Before that let's identify those obs \n",
    "# I want to chose duplication based on id, lat, and long (which represents the address of the property).\n",
    "\n",
    "print(df[['id', 'lat', 'long']].dtypes) #it is easier if our variables are not object or string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d542b813",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.duplicated(subset=['id', 'lat', 'long'], keep=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6451d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify duplicate rows based on ID and Name in a subset of columns\n",
    "dup_mask = df.duplicated(subset=['id', 'host id', 'lat', 'long'], keep=False)\n",
    "\n",
    "# filter the original dataframe to show only the duplicate rows\n",
    "dup_df = df[dup_mask].sort_values(by=['id', 'lat', 'long'])\n",
    "\n",
    "# print the result\n",
    "print(dup_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94199cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are 1082 observations with duplication values. let's delete the duplications\n",
    "\n",
    "# Sort the DataFrame by the columns used to identify duplicates\n",
    "df = df.sort_values(by=['id', 'host id', 'lat', 'long'])\n",
    "\n",
    "# Drop duplicates, keeping the first occurrence of each\n",
    "df = df.drop_duplicates(subset=['id', 'host id', 'lat', 'long'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b84dad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987f1495",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06bf123",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc93872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, let's replace the missing 'house_rules' column with the word 'blank'\n",
    "\n",
    "df.loc[df.house_rules.isnull(), 'house_rules'] = 'blank'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86852124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our next varable with many missing is 'last review'\n",
    "\n",
    "df['last review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f18135b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# since it is a date, let's start by fixing the date format\n",
    "\n",
    "df['last review'] = pd.to_datetime(df['last review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c9f2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's check the min and max for this variable so that we can change the missing accordingly\n",
    "\n",
    "df['last review'].min(), df['last review'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1972886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BINGO! we find another flaw in our dataset. the year obviously cannot be 2058. let's find other suckers that have a wrong date\n",
    "\n",
    "df[df['last review'].apply(lambda x: x.year) > 2022]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64f7598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can change these reviews with a median or mean of the date if we want to keep them. I rather just drop them. if you wanted\n",
    "# to keep them use below code\n",
    "\n",
    "#df.loc[df[df['last review'].apply(lambda x: x.year) > 2022].index, 'last review'] = df['last review'].median()\n",
    "\n",
    "df = df.drop(df[df['last review'] > pd.Timestamp('2022-12-31')].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840aaa53",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['last review'].min(), df['last review'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bb6c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's impute the null values to the minimum date in the dataset\n",
    "\n",
    "df.loc[df['last review'].isnull(), 'last review'] = df['last review'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837c6aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the null counts once again\n",
    "\n",
    "df.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b879fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, let's explore the 'reviews per month' column\n",
    "\n",
    "fig = px.histogram(df, x='reviews per month', log_y=True, )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4bb5c3",
   "metadata": {},
   "source": [
    "**How to deal with right skewed data like this?**\n",
    "\n",
    "*According to the ChatGPT*\n",
    "\n",
    "If a dataset is severely right-skewed, meaning that the majority of the data is clustered towards the lower end of the range and there are a few high values that are far from the rest, then replacing missing values with the median may not be the best option.\n",
    "\n",
    "In such cases, it's important to analyze the data and understand the reasons behind the skewness. If the skewness is due to outliers or extreme values, then replacing missing values with the median can be a good option. However, if the skewness is due to the nature of the data, such as income or age, then replacing missing values with the median may not be the best approach.\n",
    "\n",
    "Other options for dealing with missing values in a severely skewed dataset include:\n",
    "\n",
    "Using mean or mode: In some cases, the mean or mode may be a better representation of the data than the median.\n",
    "Imputing values using a regression model: This method involves using a regression model to predict the missing values based on the values of other variables.\n",
    "Deleting the missing values: If the proportion of missing values is relatively small, then it may be appropriate to simply delete the missing values. However, this method can lead to a reduction in sample size and potentially bias the results.\n",
    "\n",
    "**the histogram shows the existance of outliers, so we can replace the missing with median**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87123712",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_A = df['reviews per month'].median()\n",
    "print(\"Median of column 'A':\", median_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95baa532",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['reviews per month'].isnull(), 'reviews per month'] = 0.74"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b68d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is one of my favorite piece of code. How many unique values exists in each columns?\n",
    "\n",
    "unique_counts = df.nunique()\n",
    "print(unique_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6615450f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a variable with limited number of unique obs, we can see the frequency of each\n",
    "\n",
    "\n",
    "df.host_identity_verified.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ece1fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.cancellation_policy.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa6db11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['neighbourhood group'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68af84a",
   "metadata": {},
   "source": [
    "**did you see what just happened?** the different variable names require different ways of getting value counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5031304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the next couple of code blocks we try to make some changes based on our previous observations \n",
    "\n",
    "# Impute NAME column with 'blank'\n",
    "df.loc[df['NAME'].isnull(), 'NAME'] = 'blank'   \n",
    "\n",
    "# Impute host id with 0\n",
    "df.loc[df['host id'].isnull(), 'host id'] = 0  \n",
    "\n",
    "# Impute host_identity_verified with 'unconfirmed'\n",
    "df.loc[df['host_identity_verified'].isnull(), 'host_identity_verified'] = 'unconfirmed'\n",
    "\n",
    "# Impute host name with 'blank'\n",
    "df.loc[df['host name'].isnull(), 'host name'] = 'blank'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c4fda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix the spellings of manhattan and brooklyn in column 'neighbourhood group' and impute missing using lat/long\n",
    "df.loc[df['neighbourhood group']=='manhatan', 'neighbourhood group'] = 'Manhattan'\n",
    "df.loc[df['neighbourhood group']=='brookln', 'neighbourhood group'] = 'Brooklyn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d689761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's drop 'country' and 'country code' because they have zero variability\n",
    "df.drop(['country', 'country code'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c27c1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# since our lat and long variables have minimal missing obs, we use them to fill out our neighborhood variable\n",
    "!pip install geopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8bf534",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "geolocator = Nominatim(user_agent=\"MyApp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b045ad2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the missing neighbourhood rows\n",
    "\n",
    "df.loc[df.neighbourhood.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868fb159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define a function to accept coordinates and return suburb name\n",
    "def loc_from_coord(lat, long):\n",
    "    location = geolocator.reverse(str(lat)+\",\"+str(long))\n",
    "    return location.raw['address'].get('road', '')\n",
    "\n",
    "# Let's test the function\n",
    "temp = df.loc[df.neighbourhood.isnull()].copy()\n",
    "print(loc_from_coord(temp.iloc[0].lat, temp.iloc[0].long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467b256e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So the sample worked, now we impute all the missing neighbourhood data\n",
    "\n",
    "idx = df.loc[df.neighbourhood.isnull()].index\n",
    "df.loc[idx, 'neighbourhood'] = df.loc[idx].apply(lambda x: \\\n",
    "                                                loc_from_coord(x.lat, x.long), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0d14c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "del temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559bf3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check whether the imputation worked or not\n",
    "df.loc[idx].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cef155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okay, so that worked. Now we'll impute 'neighbourhood group'\n",
    "# Let's check the rows\n",
    "df.loc[df['neighbourhood group'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88155bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's a long list. Let's make a function to convert the coordinates to neighbourhood group\n",
    "\n",
    "def neigh_from_coord(lat,long):\n",
    "    location = geolocator.reverse(str(lat)+\",\"+str(long))\n",
    "    return location.raw['address'].get('suburb', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6a16d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check a sample\n",
    "idx = df.loc[df['neighbourhood group'].isnull()].index\n",
    "print(neigh_from_coord(df.loc[idx].iloc[0].lat, df.loc[idx].iloc[0].long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6af54c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So the sample worked, now we impute all the missing neighbourhood group data\n",
    "\n",
    "df.loc[idx, 'neighbourhood group'] = df.loc[idx].apply(lambda x: neigh_from_coord(x.lat, x.long), \n",
    "                                                       axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05f90ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check whether the imputation worked or not - choose a subset of dataframe\n",
    "df.loc[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6dcd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okay, so that worked. Let's now try to impute lat/long using neighbourhood group and neighbourhood\n",
    "df.loc[df.lat.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4adc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's collect the indices as earlier (lat and long are missing together)\n",
    "idx = df.loc[df.lat.isnull()].index\n",
    "\n",
    "# Now we define a function to accept the location and return latitude and longitude\n",
    "def lat_from_loc(loc):\n",
    "    location = geolocator.geocode(loc)\n",
    "    return location.latitude\n",
    "\n",
    "def long_from_loc(loc):\n",
    "    location = geolocator.geocode(loc)\n",
    "    return location.longitude\n",
    "\n",
    "# Let's test a sample case\n",
    "print(lat_from_loc(df.loc[idx].iloc[0].neighbourhood), long_from_loc(df.loc[idx].iloc[0].neighbourhood))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d79439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that looks pretty good, let's impute all the missing coordinates (used both neighbourhood and \n",
    "# neighbourhood group because there can be multiple suburbs with same name, such as, Elmhurst is also in IL)\n",
    "\n",
    "df.loc[idx, 'lat'] = df.loc[idx].apply(lambda x: lat_from_loc(x.neighbourhood+', '+x['neighbourhood group']), axis=1)\n",
    "df.loc[idx, 'long'] = df.loc[idx].apply(lambda x: long_from_loc(x.neighbourhood+', '+x['neighbourhood group']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94c03cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1846d20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So now we'll check for null values again, data cleaning is always a long process, and I'm not the most efficient\n",
    "\n",
    "df.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e93c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check 'availability 365'\n",
    "fig = px.histogram(df, x='availability 365')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e52d2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.box(df, y='availability 365')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c5e1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_A = df['availability 365'].median()\n",
    "print(\"availability 365 :\", median_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2aa907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We impute availability 365 with median value 96\n",
    "df['availability 365'] = df['availability 365'].fillna(96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde77232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check minimum nights\n",
    "fig = px.histogram(df, x='minimum nights')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b3cd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are many things wrong with this variable. negative numbers for minimum night? and some really high numbers\n",
    "\n",
    "df['minimum nights'].min(), df['minimum nights'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b4f49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll take log normal\n",
    "fig = px.histogram(df, x='minimum nights', log_y=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e2400e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's clip the data between 0 and 13, the upper fence (Q3 + 1.5 * IQR)\n",
    "df['minimum nights'].clip(lower=0, upper=13, inplace=True)\n",
    "fig = px.histogram(df, x='minimum nights', log_y=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb909d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.box(df, y='minimum nights', log_y=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d44b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's impute the 'minimum nights' feature with the median 3\n",
    "\n",
    "df['minimum nights'] = df['minimum nights'].fillna(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8007dec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the price feature\n",
    "# First we'll convert price from object to numeric\n",
    "import re\n",
    "\n",
    "idx = df.loc[~df.price.isnull()].index\n",
    "df.loc[idx, 'price'] = df.loc[idx].apply(lambda x: re.sub(r'\\D', '', x.price), axis=1)\n",
    "df.loc[idx, 'price'] = pd.to_numeric(df['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61687f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df.price[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275d8e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df, x='price')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe3a744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# since the mean and median are close, we use mean to replace missing variables\n",
    "\n",
    "df.price.fillna(df.price.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bff4380",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eaa0907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check service fee\n",
    "df['service fee'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385c84b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll give same treatment to service fee as price\n",
    "idx = df.loc[~df['service fee'].isnull()].index\n",
    "df.loc[idx, 'service fee'] = df.loc[idx].apply(lambda x: re.sub(r'\\D', '', x['service fee']), axis=1)\n",
    "df.loc[idx, 'service fee'] = pd.to_numeric(df['service fee'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41827e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df['service fee'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ec71a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df, x='service fee')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712f50be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['service fee'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2327db55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's impute the service fee with mean\n",
    "df['service fee'].fillna(df['service fee'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56d5e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us take the following cumulative actions:\n",
    "# 1. Check the distribution and impute review rate number\n",
    "# 2. Check the distribution and impute Construction year\n",
    "# 3. Check the distribution and impute number of reviews\n",
    "# 4. Check the distribution and impute calculated host listings count\n",
    "# 5. Check the unique values and impute instant_bookable\n",
    "# 6. Check the unique values and impute cancellation_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1edb441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# review rate number\n",
    "fig = px.box(df, y='review rate number')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620a4d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's a modest distribution, we'll impute with median\n",
    "df['review rate number'].fillna(df['review rate number'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9913c6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construction year\n",
    "fig = px.box(df, y='Construction year')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b37ffb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute with median\n",
    "df['Construction year'].fillna(df['Construction year'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb5d64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of reviews\n",
    "fig = px.histogram(df, x='number of reviews')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b70f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It has a heavy right skew, let's check log transform\n",
    "fig = px.histogram(df, x='number of reviews', log_y=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4519a7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.box(df, y='number of reviews', log_y=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c294330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute with median\n",
    "df['number of reviews'].fillna(df['number of reviews'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a514cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculated host listings count\n",
    "fig = px.histogram(df, x='calculated host listings count')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55fcb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It has a heavy right skew, let's check log transform\n",
    "fig = px.histogram(df, x='calculated host listings count', log_y=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d619f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute with median\n",
    "df['calculated host listings count'].fillna(df['calculated host listings count'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f254aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the unique values and impute instant_bookable\n",
    "df.instant_bookable.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0150b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Giving the host benefit of doubt, impute the column with True\n",
    "df.instant_bookable.fillna(True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8270ddfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the unique values and impute cancellation_policy\n",
    "df.cancellation_policy.value_counts(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2968caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again,giving host benefit of doubt, impute with 'moderate'\n",
    "df.cancellation_policy.fillna('moderate', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80be1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final check for null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49262326",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['neighbourhood group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4569d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the single occurance of 'The Bronx'\n",
    "df.loc[df['neighbourhood group']=='The Bronx', 'neighbourhood group']='Bronx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ccb1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the column headers for later ease of usage\n",
    "df.columns = df.columns.str.lower().str.replace(' ','_')\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f132f1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's export our clean data \n",
    "df.to_csv('airbnb_nyc_clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8510e7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
